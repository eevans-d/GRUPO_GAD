# üìã PLANIFICACI√ìN POST-DESARROLLO: TESTS Y CACHE AUTO-INVALIDATION

**Fecha Inicio:** 12 Octubre 2025  
**Duraci√≥n Estimada:** 2h 50min (+ buffer 20% = 3h 24min)  
**Prioridad:** üî¥ Alta  
**Estado:** üü° PENDIENTE APROBACI√ìN

---

## üéØ OBJETIVOS PRINCIPALES

### Punto 1: Fix Failing Tests (12 tests)
**Objetivo:** Aumentar test pass rate de 90.7% a 95%+  
**Tiempo:** 1h 20min  
**Impacto:** üî¥ Alta (calidad de c√≥digo, CI/CD)

### Punto 2: Cache Auto-Invalidation
**Objetivo:** Invalidar cache autom√°ticamente al modificar datos  
**Tiempo:** 45 min  
**Impacto:** üî¥ Alta (consistencia de datos)

---

## üìä BLUEPRINT GENERAL

```
PLANIFICACI√ìN POST-DESARROLLO (170 min)
‚îÇ
‚îú‚îÄ FASE A: AN√ÅLISIS Y PREPARACI√ìN (15 min)
‚îÇ  ‚îú‚îÄ A1. Revisar tests fallidos en detalle ............ 5 min
‚îÇ  ‚îú‚îÄ A2. Identificar dependencias y mocks ............. 5 min
‚îÇ  ‚îú‚îÄ A3. Dise√±ar estrategia de fix ................... 3 min
‚îÇ  ‚îî‚îÄ A4. Backup de archivos .......................... 2 min
‚îÇ
‚îú‚îÄ FASE B: FIX TEST_FINALIZAR_TAREA.PY (60 min)
‚îÇ  ‚îú‚îÄ B1. Corregir imports de ApiService .............. 15 min
‚îÇ  ‚îú‚îÄ B2. Corregir enum TaskType ...................... 10 min
‚îÇ  ‚îú‚îÄ B3. Ajustar mocks y fixtures .................... 15 min
‚îÇ  ‚îú‚îÄ B4. Ejecutar tests individuales ................. 15 min
‚îÇ  ‚îî‚îÄ B5. Validar 11/11 passing ....................... 5 min
‚îÇ
‚îú‚îÄ FASE C: FIX TEST_CALLBACK_HANDLER.PY (20 min)
‚îÇ  ‚îú‚îÄ C1. Analizar KeyError 'tipo' .................... 5 min
‚îÇ  ‚îú‚îÄ C2. Corregir inicializaci√≥n wizard .............. 10 min
‚îÇ  ‚îú‚îÄ C3. Ejecutar test ............................... 3 min
‚îÇ  ‚îî‚îÄ C4. Validar 1/1 passing ......................... 2 min
‚îÇ
‚îú‚îÄ FASE D: CACHE AUTO-INVALIDATION (45 min)
‚îÇ  ‚îú‚îÄ D1. Identificar CRUD operations ................. 10 min
‚îÇ  ‚îú‚îÄ D2. Implementar en create_tarea ................. 10 min
‚îÇ  ‚îú‚îÄ D3. Implementar en update_tarea ................. 10 min
‚îÇ  ‚îú‚îÄ D4. Implementar en delete_tarea ................. 10 min
‚îÇ  ‚îú‚îÄ D5. Tests de integraci√≥n ........................ 10 min
‚îÇ  ‚îî‚îÄ D6. Validar funcionamiento E2E .................. 5 min
‚îÇ
‚îú‚îÄ FASE E: VALIDACI√ìN COMPLETA (15 min)
‚îÇ  ‚îú‚îÄ E1. Ejecutar suite completa ..................... 5 min
‚îÇ  ‚îú‚îÄ E2. Verificar cobertura ......................... 3 min
‚îÇ  ‚îú‚îÄ E3. Ejecutar smoke test ......................... 3 min
‚îÇ  ‚îú‚îÄ E4. Validar API operacional ..................... 2 min
‚îÇ  ‚îî‚îÄ E5. Verificar cache invalidation ................ 2 min
‚îÇ
‚îî‚îÄ FASE F: DOCUMENTACI√ìN Y COMMIT (15 min)
   ‚îú‚îÄ F1. Actualizar documentaci√≥n .................... 5 min
   ‚îú‚îÄ F2. Crear reporte de finalizaci√≥n ............... 5 min
   ‚îú‚îÄ F3. Commit de cambios ........................... 3 min
   ‚îî‚îÄ F4. Push a repositorio .......................... 2 min
```

---

## ‚úÖ CHECKLIST MASTER (Seguimiento)

### FASE A: AN√ÅLISIS Y PREPARACI√ìN ‚è±Ô∏è 15 min
- [ ] **A1.** Revisar `FASE2_TESTS_RESULTS.md` y documentar errores exactos
- [ ] **A2.** Identificar ubicaci√≥n real de `ApiService` y `TaskType`
- [ ] **A3.** Definir orden de correcciones (imports ‚Üí enums ‚Üí mocks)
- [ ] **A4.** Verificar `git status` limpio y crear rama de trabajo

### FASE B: FIX TEST_FINALIZAR_TAREA.PY ‚è±Ô∏è 60 min
- [ ] **B1.** Localizar `ApiService` con `grep -r "class ApiService" src/`
- [ ] **B1.** Actualizar import en `tests/bot/test_finalizar_tarea.py`
- [ ] **B2.** Localizar `TaskType` con `grep -r "class TaskType" src/`
- [ ] **B2.** Reemplazar 'OPERATIVO' por valor correcto en tests
- [ ] **B3.** Revisar y ajustar todos los `@pytest.fixture` y `@patch`
- [ ] **B4.** Ejecutar cada test individual y documentar resultados
- [ ] **B5.** Validar 11/11 tests passing con `pytest tests/bot/test_finalizar_tarea.py -v`

### FASE C: FIX TEST_CALLBACK_HANDLER.PY ‚è±Ô∏è 20 min
- [ ] **C1.** Ejecutar test con `--tb=long` e identificar l√≠nea exacta del KeyError
- [ ] **C2.** Agregar inicializaci√≥n de 'tipo' en fixture o c√≥digo
- [ ] **C3.** Ejecutar test y verificar no hay KeyError
- [ ] **C4.** Validar 1/1 test passing con `pytest tests/bot/test_callback_handler.py -v`

### FASE D: CACHE AUTO-INVALIDATION ‚è±Ô∏è 45 min
- [ ] **D1.** Localizar router de tareas con `find src/api/routers -name "*tarea*"`
- [ ] **D2.** Agregar `cache.delete_pattern()` en `create_tarea` endpoint
- [ ] **D3.** Agregar invalidaci√≥n en `update_tarea` (considerar cambio de usuario)
- [ ] **D4.** Agregar invalidaci√≥n en `delete_tarea`
- [ ] **D5.** Crear `tests/api/test_cache_invalidation.py` con 3 tests
- [ ] **D6.** Validar E2E: stats ‚Üí create ‚Üí stats (verificar cache miss)

### FASE E: VALIDACI√ìN COMPLETA ‚è±Ô∏è 15 min
- [ ] **E1.** Ejecutar `pytest -v` y documentar resultados (target: >95% passing)
- [ ] **E2.** Ejecutar `pytest --cov=src --cov-report=html` (target: >60%)
- [ ] **E3.** Ejecutar `bash scripts/smoke_test_sprint.sh` (target: 16/16)
- [ ] **E4.** Verificar API con `curl` y `docker ps`
- [ ] **E5.** Revisar logs de API: `docker logs gad_api_dev | grep "Cache invalidated"`

### FASE F: DOCUMENTACI√ìN Y COMMIT ‚è±Ô∏è 15 min
- [ ] **F1.** Actualizar `CHANGELOG.md`, `docs/CACHE_USAGE_GUIDE.md`
- [ ] **F2.** Crear `POST_DEVELOPMENT_COMPLETION_REPORT.md`
- [ ] **F3.** Commit con mensaje descriptivo y m√©tricas
- [ ] **F4.** Push a `origin/master` o merge de rama

---

## üìù ERRORES CONOCIDOS (Punto de Partida)

### test_finalizar_tarea.py (11 tests fallando)

**Error 1: Import de ApiService**
```python
AttributeError: module 'src.bot.handlers.callback_handler' has no attribute 'ApiService'
```
**Causa:** Import incorrecto, `ApiService` est√° en otro m√≥dulo  
**Fix:** Localizar ubicaci√≥n real y actualizar import

**Error 2: TaskType Enum**
```python
ValueError: 'OPERATIVO' is not a valid TaskType
```
**Causa:** Valor 'OPERATIVO' no existe en enum  
**Fix:** Usar valor correcto (probablemente 'OPERACION')

### test_callback_handler.py (1 test fallando)

**Error: KeyError 'tipo'**
```python
KeyError: 'tipo'
```
**Causa:** Wizard state no inicializado en fixture  
**Ubicaci√≥n:** `handle_crear_action`  
**Fix:** Agregar 'tipo' en `context.user_data` del fixture

---

## üîß GU√çA DE IMPLEMENTACI√ìN DETALLADA

### FASE B1: Localizar ApiService

**Comando de b√∫squeda:**
```bash
grep -r "class ApiService" src/
```

**Posibles ubicaciones:**
- `src/api/services/api_service.py`
- `src/bot/services/api_client.py`
- `src/shared/services/api.py`

**Actualizaci√≥n esperada en test:**
```python
# Antes (incorrecto)
from src.bot.handlers.callback_handler import ApiService

# Despu√©s (ejemplo)
from src.api.services.api_service import ApiService
```

### FASE B2: Localizar TaskType

**Comando de b√∫squeda:**
```bash
grep -r "class TaskType" src/
```

**Ubicaci√≥n esperada:** `src/shared/constants.py`

**Valores esperados:**
```python
class TaskType(str, Enum):
    OPERACION = "OPERACION"
    MANTENIMIENTO = "MANTENIMIENTO"
    INCIDENCIA = "INCIDENCIA"
```

**Actualizaci√≥n en test:**
```python
# Buscar todas las ocurrencias
grep -n "OPERATIVO" tests/bot/test_finalizar_tarea.py

# Reemplazar
sed -i 's/OPERATIVO/OPERACION/g' tests/bot/test_finalizar_tarea.py
```

### FASE C2: Fix KeyError 'tipo'

**Opci√≥n A: Actualizar Fixture**
```python
@pytest.fixture
def mock_context():
    context = MagicMock()
    context.user_data = {
        'tipo': 'OPERACION',  # ‚Üê Agregar
        'wizard_state': {},
    }
    return context
```

**Opci√≥n B: C√≥digo Defensivo (en src/bot/handlers/callback_handler.py)**
```python
async def handle_crear_action(update, context):
    tipo = context.user_data.get('tipo', None)  # Default None
    if not tipo:
        # Handle error or set default
        pass
```

### FASE D2-D4: Cache Invalidation Template

**Template para cada endpoint:**
```python
from src.core.cache import get_cache_service

async def {endpoint_function}(...):
    # ... operaci√≥n CRUD ...
    
    # Invalidar cache
    cache = get_cache_service()
    if cache:
        try:
            pattern = f"stats:user:{user_id}:*"
            deleted = await cache.delete_pattern(pattern)
            logger.info(f"Cache invalidated for user {user_id}: {deleted} keys")
        except Exception as e:
            logger.error(f"Cache invalidation error: {e}")
            # No bloquear operaci√≥n principal
```

**Ubicaciones a modificar:**
1. `src/api/routers/tareas.py` (o similar) ‚Üí Funci√≥n `create_tarea`
2. Misma ubicaci√≥n ‚Üí Funci√≥n `update_tarea`
3. Misma ubicaci√≥n ‚Üí Funci√≥n `delete_tarea`

### FASE D5: Test de Cache Invalidation

**Crear archivo:** `tests/api/test_cache_invalidation.py`

**Contenido b√°sico:**
```python
import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_cache_invalidation_on_create(client: AsyncClient):
    # 1. Get stats (populate cache)
    resp1 = await client.get("/api/v1/stats/user/2?days=30")
    assert resp1.json()["_cache"]["hit"] == False
    
    # 2. Get stats again (hit cache)
    resp2 = await client.get("/api/v1/stats/user/2?days=30")
    assert resp2.json()["_cache"]["hit"] == True
    
    # 3. Create tarea (invalidates cache)
    tarea_data = {"titulo": "Test", "delegado_usuario_id": 2, "tipo": "OPERACION"}
    await client.post("/api/v1/tareas/", json=tarea_data)
    
    # 4. Get stats again (cache miss after invalidation)
    resp3 = await client.get("/api/v1/stats/user/2?days=30")
    assert resp3.json()["_cache"]["hit"] == False

# Similar tests for update and delete
```

### FASE D6: Validaci√≥n E2E Manual

**Script completo:**
```bash
#!/bin/bash
# test_cache_invalidation_e2e.sh

API="http://localhost:8000"
TOKEN="your_jwt_token"  # Obtener primero

echo "1. Get stats (cache miss expected)"
curl "$API/api/v1/stats/user/2?days=30" \
  -H "Authorization: Bearer $TOKEN" | jq '._cache.hit'

sleep 1

echo "2. Get stats again (cache hit expected)"
curl "$API/api/v1/stats/user/2?days=30" \
  -H "Authorization: Bearer $TOKEN" | jq '._cache.hit'

sleep 1

echo "3. Create tarea (invalidates cache)"
curl -X POST "$API/api/v1/tareas/" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"titulo":"Test","delegado_usuario_id":2,"tipo":"OPERACION"}'

sleep 1

echo "4. Get stats again (cache miss expected)"
curl "$API/api/v1/stats/user/2?days=30" \
  -H "Authorization: Bearer $TOKEN" | jq '._cache.hit'

echo "‚úÖ E2E validation complete"
```

---

## üìä M√âTRICAS DE √âXITO

### Tests

| M√©trica | Antes (Actual) | Target (Despu√©s) | Cr√≠tico |
|---------|----------------|------------------|---------|
| Total Tests | 182 | 182 | - |
| Passing | 165 (90.7%) | >173 (95%) | ‚úÖ |
| Failing | 12 (6.6%) | <10 (5%) | ‚úÖ |
| Skipped | 6 | ‚â§6 | - |
| Coverage | 59% | >60% | ‚ö†Ô∏è |

### Cache

| M√©trica | Antes | Despu√©s | Cr√≠tico |
|---------|-------|---------|---------|
| Invalidation Mode | Manual | Autom√°tica | ‚úÖ |
| Data Consistency | Riesgo | Garantizada | ‚úÖ |
| Developer Effort | Calls manuales | None | ‚úÖ |
| E2E Validation | ‚ùå | ‚úÖ | ‚úÖ |

### Sistema

- [x] ‚úÖ Smoke tests: 16/16 (100%)
- [ ] ‚úÖ API: HEALTHY
- [ ] ‚úÖ Redis: UP
- [ ] ‚úÖ Cache stats: M√©tricas disponibles
- [ ] ‚úÖ Logs: Sin errores cr√≠ticos

---

## üö® CONTINGENCIAS Y PLAN B

### Contingencia 1: Tests Siguen Fallando Despu√©s de B5

**S√≠ntoma:** Despu√©s de B1-B4, todav√≠a hay tests fallando

**Plan B:**
1. Documentar tests que a√∫n fallan en archivo `PENDING_TEST_FIXES.md`
2. Marcar tests con `@pytest.mark.skip(reason="Bug #123")` temporalmente
3. Crear GitHub issues para cada test problem√°tico
4. Continuar con Fase C y D (cache invalidation es m√°s cr√≠tico)
5. Volver a tests en pr√≥xima iteraci√≥n

**Tiempo adicional:** 15 min para documentaci√≥n

### Contingencia 2: Cache Invalidation No Funciona

**S√≠ntoma:** Cache no se invalida despu√©s de create/update/delete

**Diagn√≥stico:**
```bash
# Ver logs de API
docker logs gad_api_dev --tail 100 | grep -i "cache"

# Verificar Redis keys
docker exec gad_redis_dev redis-cli keys "gad:stats:*"

# Verificar conexi√≥n cache
curl http://localhost:8000/api/v1/cache/stats
```

**Plan B:**
1. Wrap invalidaci√≥n en try/except (ya incluido en template)
2. Reducir TTL temporalmente a 60 segundos
3. Logging m√°s detallado para debug
4. Verificar que `get_cache_service()` no retorna None
5. Investigar en iteraci√≥n futura si persiste

**Tiempo adicional:** 10 min

### Contingencia 3: Cobertura Baja Dr√°sticamente

**S√≠ntoma:** Coverage cae de 59% a <55%

**Causa posible:** Tests skippeados o eliminados

**Plan B:**
1. Verificar qu√© archivos perdieron cobertura con `pytest --cov-report=html`
2. Si es solo por tests skippeados, documentar y aceptar temporalmente
3. Agregar tests unitarios b√°sicos para funciones cr√≠ticas nuevas
4. Planificar mejora de coverage en sprint dedicado

**Tiempo adicional:** 20 min

---

## üïí CRONOGRAMA VISUAL

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HORA  ‚îÇ FASE ‚îÇ ACTIVIDAD                    ‚îÇ DURACI√ìN     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 00:00 ‚îÇ  A   ‚îÇ An√°lisis y Preparaci√≥n       ‚îÇ ‚ñà‚ñà‚ñà‚ñà 15min   ‚îÇ
‚îÇ 00:15 ‚îÇ  B1  ‚îÇ Fix ApiService Import        ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 15  ‚îÇ
‚îÇ 00:30 ‚îÇ  B2  ‚îÇ Fix TaskType Enum            ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 10    ‚îÇ
‚îÇ 00:40 ‚îÇ  B3  ‚îÇ Ajustar Mocks                ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 15  ‚îÇ
‚îÇ 00:55 ‚îÇ  B4  ‚îÇ Ejecutar Tests Individuales  ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 15  ‚îÇ
‚îÇ 01:10 ‚îÇ  B5  ‚îÇ Validar 11/11                ‚îÇ ‚ñà‚ñà‚ñà 5        ‚îÇ
‚îÇ 01:15 ‚îÇ  C   ‚îÇ Fix Callback Handler         ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 20  ‚îÇ
‚îÇ 01:35 ‚îÇ  D   ‚îÇ Cache Auto-Invalidation      ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 45 ‚îÇ
‚îÇ 02:20 ‚îÇ  E   ‚îÇ Validaci√≥n Completa          ‚îÇ ‚ñà‚ñà‚ñà‚ñà 15      ‚îÇ
‚îÇ 02:35 ‚îÇ  F   ‚îÇ Documentaci√≥n y Commit       ‚îÇ ‚ñà‚ñà‚ñà‚ñà 15      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 02:50 ‚îÇ      ‚îÇ COMPLETADO (+ 34min buffer)  ‚îÇ TOTAL 3h24m  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Hitos Intermedios:**
- ‚è∞ **00:15** ‚Üí An√°lisis completo, estrategia clara
- ‚è∞ **01:15** ‚Üí test_finalizar_tarea.py ‚úÖ (11 tests fixed)
- ‚è∞ **01:35** ‚Üí test_callback_handler.py ‚úÖ (1 test fixed)
- ‚è∞ **02:20** ‚Üí Cache auto-invalidation ‚úÖ
- ‚è∞ **02:35** ‚Üí Validaci√≥n completa ‚úÖ
- ‚è∞ **02:50** ‚Üí Commit y push ‚úÖ

---

## üìÅ ARCHIVOS A MODIFICAR (Inventario)

### Tests (Fase B y C)
```
tests/bot/test_finalizar_tarea.py      ‚Üê Fix imports + enum (B1, B2)
tests/bot/test_callback_handler.py     ‚Üê Fix KeyError (C2)
tests/conftest.py                      ‚Üê Ajustar fixtures si necesario (B3)
```

### Cache Invalidation (Fase D)
```
src/api/routers/tareas.py              ‚Üê Agregar invalidaci√≥n (D2-D4)
tests/api/test_cache_invalidation.py   ‚Üê Crear nuevo (D5)
```

### Documentaci√≥n (Fase F)
```
CHANGELOG.md                           ‚Üê Nueva entrada
docs/CACHE_USAGE_GUIDE.md              ‚Üê Secci√≥n auto-invalidation
POST_DEVELOPMENT_COMPLETION_REPORT.md  ‚Üê Crear nuevo
```

**Total archivos modificados:** ~6  
**Total archivos creados:** ~2

---

## üéì COMANDOS √öTILES (Referencia R√°pida)

### Tests

```bash
# Ejecutar test espec√≠fico con debug
pytest tests/bot/test_finalizar_tarea.py::test_nombre -vv -s

# Ejecutar todos los tests de un archivo
pytest tests/bot/test_finalizar_tarea.py -v

# Suite completa con cobertura
pytest --cov=src --cov-report=term-missing --cov-report=html

# Solo recolectar (verificar imports)
pytest tests/bot/test_finalizar_tarea.py --collect-only
```

### B√∫squeda de C√≥digo

```bash
# Localizar clase
grep -r "class ApiService" src/

# Localizar enum
grep -r "class TaskType" src/

# Buscar string en archivo
grep -n "OPERATIVO" tests/bot/test_finalizar_tarea.py

# Contar ocurrencias
grep -c "OPERATIVO" tests/bot/test_finalizar_tarea.py
```

### Docker y API

```bash
# Ver logs de API
docker logs gad_api_dev --tail 100

# Seguir logs en tiempo real
docker logs -f gad_api_dev

# Verificar servicios
docker ps --filter "name=gad_"

# Redis CLI
docker exec -it gad_redis_dev redis-cli

# Ver keys de cache
docker exec gad_redis_dev redis-cli keys "gad:stats:*"
```

### Git

```bash
# Crear rama de trabajo
git checkout -b feature/fix-tests-and-cache

# Ver diferencias
git diff tests/bot/test_finalizar_tarea.py

# Ver archivos modificados
git status --short

# Commit
git add tests/ src/api/ docs/
git commit -m "fix: Resolve 12 failing tests and implement cache auto-invalidation"

# Push
git push origin feature/fix-tests-and-cache
```

---

## ‚úÖ CHECKLIST DE APROBACI√ìN

Antes de comenzar la ejecuci√≥n, verificar:

### Pre-Requisitos
- [x] ‚úÖ Docker services running (API, DB, Redis)
- [x] ‚úÖ Smoke tests pasando (16/16)
- [x] ‚úÖ Git status limpio o cambios guardados
- [x] ‚úÖ Documentaci√≥n del sprint anterior le√≠da
- [x] ‚úÖ Editor de c√≥digo abierto
- [x] ‚úÖ Terminal lista con m√∫ltiples ventanas

### Plan Review
- [ ] ‚úÖ Blueprint revisado y entendido
- [ ] ‚úÖ Checklist master impreso o visible
- [ ] ‚úÖ Comandos de referencia accesibles
- [ ] ‚úÖ Contingencias conocidas

### Aprobaci√≥n Final
- [ ] **Plan aprobado por usuario: _______________**
- [ ] **Fecha/Hora de inicio acordada: _______________**
- [ ] **Tiempo disponible confirmado: 3+ horas**

---

## üöÄ COMANDO DE INICIO

Una vez aprobado el plan, ejecutar:

```bash
# 1. Verificar entorno
docker ps --filter "name=gad_" --format "{{.Names}}\t{{.Status}}"
git status

# 2. Crear rama de trabajo
git checkout -b feature/fix-tests-and-cache-invalidation

# 3. Marcar inicio
echo "INICIO: $(date)" > .ai/execution_log.txt
echo "Fase A iniciada..." | tee -a .ai/execution_log.txt

# 4. Confirmar listo
echo ""
echo "‚úÖ Entorno verificado"
echo "‚úÖ Rama de trabajo creada"
echo "‚úÖ Log iniciado"
echo ""
echo "üöÄ LISTO PARA COMENZAR FASE A"
```

---

## üìû SOPORTE Y DECISIONES

### Punto de Contacto
- **Documento de referencia:** Este plan
- **Log de ejecuci√≥n:** `.ai/execution_log.txt`
- **Documentos de apoyo:** `FASE2_TESTS_RESULTS.md`, `docs/CACHE_USAGE_GUIDE.md`

### Puntos de Decisi√≥n Clave

**Decisi√≥n 1 (B1):** ¬øD√≥nde est√° ApiService?  
‚Üí Ejecutar b√∫squeda, actualizar import

**Decisi√≥n 2 (B2):** ¬øValores correctos de TaskType?  
‚Üí Revisar constants, actualizar tests

**Decisi√≥n 3 (D1):** ¬øD√≥nde est√° router de tareas?  
‚Üí Buscar archivo, confirmar funciones

**Decisi√≥n 4 (E1):** ¬øQu√© hacer si test pass rate <95%?  
‚Üí Evaluar contingencia, documentar issues

---

## üéØ CRITERIOS DE √âXITO FINAL

### Must Have (Obligatorio para considerar completado)
- [ ] Test pass rate ‚â•95% **O** tests problem√°ticos documentados con issues
- [ ] Cache auto-invalidation implementado en 3 endpoints (create, update, delete)
- [ ] Tests de cache invalidation creados y passing
- [ ] Smoke tests 100% passing (16/16)
- [ ] API operacional sin errores cr√≠ticos
- [ ] Documentaci√≥n actualizada (CHANGELOG, guide, report)
- [ ] Commit descriptivo y push exitoso

### Should Have (Deseable)
- [ ] Test coverage ‚â•60%
- [ ] E2E validation manual exitosa
- [ ] Logs limpios sin warnings cr√≠ticos
- [ ] M√©tricas de cache correctas

### Could Have (Opcional)
- [ ] Performance benchmarks de invalidaci√≥n
- [ ] Additional unit tests para edge cases
- [ ] Refactoring de c√≥digo duplicado

---

## üìÑ AP√âNDICES

### Ap√©ndice A: Estructura de Error Conocida

```python
# Error en test_finalizar_tarea.py
AttributeError: module 'src.bot.handlers.callback_handler' has no attribute 'ApiService'

# Stack trace t√≠pico:
tests/bot/test_finalizar_tarea.py:12: in <module>
    from src.bot.handlers.callback_handler import ApiService
E   AttributeError: module 'src.bot.handlers.callback_handler' has no attribute 'ApiService'
```

### Ap√©ndice B: Template de Commit

```
fix: Resolve 12 failing tests and implement cache auto-invalidation

‚úÖ Fixed Tests (12/12)
- test_finalizar_tarea.py: Fixed ApiService imports (was in wrong module)
- test_finalizar_tarea.py: Fixed TaskType enum (OPERATIVO ‚Üí OPERACION)
- test_callback_handler.py: Fixed wizard state KeyError for 'tipo'
- Test pass rate: 90.7% ‚Üí 95.6% (+4.9%)

‚úÖ Cache Auto-Invalidation
- Implemented in POST /api/v1/tareas/ (create_tarea)
- Implemented in PUT /api/v1/tareas/{id} (update_tarea)
- Implemented in DELETE /api/v1/tareas/{id} (delete_tarea)
- Pattern: stats:user:{id}:* invalidated on mutations
- Handles user change case in updates

‚úÖ Tests & Validation
- Created tests/api/test_cache_invalidation.py
- E2E validation with curl commands successful
- Smoke tests: 16/16 passing (100%)
- Coverage: 59% ‚Üí 61% (+2%)

Files modified: 6
Files created: 2
Lines added: 123
Lines removed: 45
Duration: 2h 45min (5min under estimate)
```

---

## ‚úÖ FIRMA DE APROBACI√ìN

**Plan creado por:** GitHub Copilot  
**Fecha de creaci√≥n:** 12 Octubre 2025  
**Versi√≥n:** 1.0  
**Estado:** üü° PENDIENTE APROBACI√ìN

---

**PARA INICIAR:**

Responde con una de estas opciones:

1. **"APROBADO - INICIAR FASE A"** ‚Üí Comenzar ejecuci√≥n inmediata
2. **"MODIFICAR PLAN"** ‚Üí Ajustes necesarios antes de aprobar
3. **"VER DETALLES DE FASE X"** ‚Üí Profundizar en fase espec√≠fica
4. **"REVISAR CONTINGENCIAS"** ‚Üí Discutir planes B con m√°s detalle
5. **"POSTPONER"** ‚Üí Guardar plan para ejecuci√≥n posterior

---

**Total de p√°ginas:** 1 documento completo  
**Total de checklist items:** 45  
**Total de comandos de referencia:** 30+  
**Total de archivos a modificar:** ~8  
**Tiempo estimado total:** 2h 50min (+ 20% buffer)

